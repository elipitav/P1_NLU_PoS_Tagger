{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HV6JSlnRhL9",
        "outputId": "4e9d63c9-bc8e-461b-c300-4b09ed9886ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading conllu-6.0.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading conllu-6.0.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install conllu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHn-SWHfRaEy",
        "outputId": "e366e651-140a-49ed-be59-d1854e882f0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[TokenList<From, the, AP, comes, this, story, :, metadata={newdoc id: \"weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713\", sent_id: \"weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0001\", newpar id: \"weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-p0001\", text: \"From the AP comes this story :\"}>, TokenList<President, Bush, on, Tuesday, nominated, two, individuals, to, replace, retiring, jurists, on, federal, courts, in, the, Washington, area, ., metadata={sent_id: \"weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-0002\", newpar id: \"weblog-blogspot.com_nominations_20041117172713_ENG_20041117_172713-p0002\", text: \"President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area.\"}>]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from conllu import parse\n",
        "\n",
        "filename = \"data/english/en_ewt-ud-dev.conllu\"\n",
        "\n",
        "\n",
        "def get_fields(line):\n",
        "    words = line.split(\"\\t\")\n",
        "    if len(words) < 4:\n",
        "        return None\n",
        "    return words[1], words[3], line\n",
        "\n",
        "\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "    sentences = parse(file.read())\n",
        "\n",
        "sentences[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXx8zmxlRbMe",
        "outputId": "e640197a-0855-444e-c6ad-19ab3e7f9d94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentences: ['From the AP comes this story :', 'President Bush on Tuesday nominated two individuals to replace retiring jurists on federal courts in the Washington area .', 'Bush nominated Jennifer M. Anderson for a 15 - year term as associate judge of the Superior Court of the District of Columbia , replacing Steffen W. Graae .', '***', 'Bush also nominated A. Noel Anketell Kramer for a 15 - year term as associate judge of the District of Columbia Court of Appeals , replacing John Montague Steadman .']\n",
            "Class labels: [['ADP', 'DET', 'PROPN', 'VERB', 'DET', 'NOUN', 'PUNCT'], ['PROPN', 'PROPN', 'ADP', 'PROPN', 'VERB', 'NUM', 'NOUN', 'PART', 'VERB', 'VERB', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'PROPN', 'NOUN', 'PUNCT'], ['PROPN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'ADP', 'DET', 'NUM', 'PUNCT', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'PROPN', 'ADP', 'DET', 'PROPN', 'ADP', 'PROPN', 'PUNCT', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT'], ['PUNCT'], ['PROPN', 'ADV', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PROPN', 'ADP', 'DET', 'NUM', 'PUNCT', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADP', 'DET', 'PROPN', 'ADP', 'PROPN', 'PROPN', 'ADP', 'PROPN', 'PUNCT', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT']]\n"
          ]
        }
      ],
      "source": [
        "X_data = []\n",
        "y_data = []\n",
        "\n",
        "for sentence in sentences:\n",
        "    parsed_sentence = []\n",
        "    sentence_labels = []\n",
        "    for token in sentence:\n",
        "        if type(token[\"id\"]) == int:\n",
        "            parsed_sentence.append(token[\"form\"])\n",
        "            sentence_labels.append(token[\"upostag\"])\n",
        "    X_data.append(\" \".join(parsed_sentence))\n",
        "    y_data.append(sentence_labels)\n",
        "\n",
        "\n",
        "print(f\"Sentences: {X_data[:5]}\")\n",
        "print(f\"Class labels: {y_data[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6fXXyQv17ZI",
        "outputId": "3b58467f-4f7a-470c-ef57-a3ef1b9d70a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4856 - loss: 2.4976\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9100 - loss: 1.0651\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9085 - loss: 0.4658\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9102 - loss: 0.3448\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9110 - loss: 0.3184\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9116 - loss: 0.3140\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9142 - loss: 0.3140\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9187 - loss: 0.3122\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9238 - loss: 0.3063\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9252 - loss: 0.3056\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780a60fb3ac0>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Map labels\n",
        "unique_tags = sorted(set(tag for sublist in y_data for tag in sublist))\n",
        "tag_to_index = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "num_tags = len(tag_to_index)\n",
        "\n",
        "# Convert labels into numbers\n",
        "y_data_indexed = [[tag_to_index[tag] for tag in sublist] for sublist in y_data]\n",
        "\n",
        "# Padding de las etiquetas (y_train) para que tengan la misma longitud\n",
        "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_data_indexed, padding=\"post\", maxlen=128)\n",
        "\n",
        "# TextVectorization\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_mode=\"int\", max_tokens=10000, output_sequence_length=128)\n",
        "text_vectorizer.adapt(X_data)\n",
        "X_data_vectorized = text_vectorizer(np.array(X_data))\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(128,), dtype=tf.int32)\n",
        "x = tf.keras.layers.Embedding(input_dim=len(text_vectorizer.get_vocabulary()), output_dim=30)(input_layer)\n",
        "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
        "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_tags, activation=\"softmax\"))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_data_vectorized, y_train, batch_size=512, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "MQcwBsScN8-L",
        "outputId": "a25b2e05-c7d7-4ec6-85d8-e8cd573d99a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Anton\\Universidade\\7_Curso\\0_Materias\\NLU\\Practicas\\nlu_venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Anton\\Universidade\\7_Curso\\0_Materias\\NLU\\Practicas\\nlu_venv\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Anton\\Universidade\\7_Curso\\0_Materias\\NLU\\Practicas\\nlu_venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Anton\\Universidade\\7_Curso\\0_Materias\\NLU\\Practicas\\nlu_venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From c:\\Users\\User\\Desktop\\Anton\\Universidade\\7_Curso\\0_Materias\\NLU\\Practicas\\nlu_venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "4/4 [==============================] - 3s 281ms/step - loss: 2.7968 - accuracy: 0.4442\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 1s 263ms/step - loss: 2.6546 - accuracy: 0.9091\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 1s 257ms/step - loss: 2.3392 - accuracy: 0.9091\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 1s 244ms/step - loss: 1.4417 - accuracy: 0.9091\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 1s 247ms/step - loss: 0.6595 - accuracy: 0.9091\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 1s 241ms/step - loss: 0.4658 - accuracy: 0.9091\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 1s 229ms/step - loss: 0.4327 - accuracy: 0.9091\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 1s 238ms/step - loss: 0.4331 - accuracy: 0.9091\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.4346 - accuracy: 0.9091\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 1s 254ms/step - loss: 0.4291 - accuracy: 0.9091\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x15bf9ce2200>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Map labels\n",
        "unique_tags = sorted(set(tag for sublist in y_data for tag in sublist))\n",
        "tag_to_index = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "num_tags = len(tag_to_index)\n",
        "\n",
        "# Convert labels into numbers\n",
        "y_data_indexed = [[tag_to_index[tag] for tag in sublist] for sublist in y_data]\n",
        "\n",
        "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_data_indexed, padding=\"post\", maxlen=128)\n",
        "\n",
        "text_vectorizer = tf.keras.layers.TextVectorization(output_mode=\"int\", max_tokens=10000, output_sequence_length=128)\n",
        "text_vectorizer.adapt(X_data)\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(input_layer)\n",
        "x = tf.keras.layers.Embedding(input_dim=len(text_vectorizer.get_vocabulary()), output_dim=30)(x)\n",
        "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
        "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_tags, activation=\"softmax\"))(x)\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=x)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(np.array(X_data), y_train, batch_size=512, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "6cyw8LrNZFQH",
        "outputId": "f58b7475-9cec-4753-d9f1-051a972bbf5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_36\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_36\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">142,230</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_40                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,105</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_42 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding_42 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m142,230\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_41 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m24,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_40                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m17\u001b[0m)             │           \u001b[38;5;34m1,105\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,655</span> (654.90 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m167,655\u001b[0m (654.90 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,655</span> (654.90 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m167,655\u001b[0m (654.90 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4859 - loss: 2.3551\n",
            "Epoch 2/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9085 - loss: 0.8369\n",
            "Epoch 3/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9096 - loss: 0.4070\n",
            "Epoch 4/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9092 - loss: 0.3301\n",
            "Epoch 5/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9088 - loss: 0.3145\n",
            "Epoch 6/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9085 - loss: 0.3107\n",
            "Epoch 7/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.9108 - loss: 0.3030\n",
            "Epoch 8/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9090 - loss: 0.3090\n",
            "Epoch 9/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9089 - loss: 0.3078\n",
            "Epoch 10/10\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9091 - loss: 0.3079\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780a639408b0>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Map labels\n",
        "unique_tags = sorted(set(tag for sublist in y_data for tag in sublist))\n",
        "tag_to_index = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "num_tags = len(tag_to_index)\n",
        "\n",
        "# Convert labels into numbers\n",
        "y_data_indexed = [[tag_to_index[tag] for tag in sublist] for sublist in y_data]\n",
        "\n",
        "# Padding de las etiquetas (y_train) para que tengan la misma longitud\n",
        "y_train = tf.keras.preprocessing.sequence.pad_sequences(y_data_indexed, padding=\"post\", maxlen=128)\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_data)\n",
        "X_data_sequences = tokenizer.texts_to_sequences(X_data)\n",
        "X_data_padded = tf.keras.preprocessing.sequence.pad_sequences(X_data_sequences, padding=\"post\", maxlen=128)\n",
        "\n",
        "input_layer = tf.keras.layers.Input(shape=(128,), dtype=tf.int32)\n",
        "x = tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=30)(input_layer)\n",
        "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
        "x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_tags, activation=\"softmax\"))(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=x)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.fit(X_data_padded, y_train, batch_size=512, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okqT5DsyzAin"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlu_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
